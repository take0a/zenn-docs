---
title: "dltÂÖ•ÈñÄ"
emoji: "üîó"
type: "tech" # tech: ÊäÄË°ìË®ò‰∫ã / idea: „Ç¢„Ç§„Éá„Ç¢
topics: ["python", "dlt", "uv", "duckdb"]
published: true
publication_name: "robon"
---

# „ÅØ„Åò„ÇÅ„Å´

ÂâçÂõû„ÅÆ dbt „Å´Á∂ö„ÅÑ„Å¶„ÄÅdlt „Åß„Åô„ÄÇdbt „ÅØ„ÄÅdata build tool„ÄÇdlt „ÅØ„ÄÅdata load tool„ÄÇ
„Åæ„ÄÅ„ÇÑ„Å£„Å¶„Åø„Åæ„Åô„ÄÇ

# „ÇÑ„Å£„Å¶„Åø„Çã

## [„Ç§„É≥„Çπ„Éà„Éº„É´](https://dlthub.com/docs/reference/installation)

uv „Åß„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çí‰Ωú„Å£„Å¶„ÄÅ„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Åæ„Åô„ÄÇ

```
$ uv init
Initialized project `dlt-getting-started`
$ uv venv
Using CPython 3.12.9
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
$ uv add dlt[duckdb]
Resolved 50 packages in 566ms
Prepared 30 packages in 164ms
Installed 43 packages in 46ms
:
 + urllib3==2.3.0
$ uv run dlt --version
dlt 1.9.0
```

## [REST API](https://dlthub.com/docs/tutorial/rest-api)

uv „ÅÆ„ÉØ„Éº„ÇØ„Çπ„Éö„Éº„Çπ„ÅÆ„É°„É≥„Éê„Éº„Å®„Åó„Å¶„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ

```
$ uv init rest-api
Adding `rest-api` as member of workspace `/home/ec2-user/work/mds/dlt-getting-started`
Initialized project `rest-api` at `/home/ec2-user/work/mds/dlt-getting-started/rest-api`
$ cd rest-api
$ uv venv
Using CPython 3.12.9
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
$ uv run dlt --version
dlt 1.9.0
```

`dlt init` „Åó„Åæ„Åô„ÄÇÈÄî‰∏≠„ÅÆË≥™Âïè„ÅØ `Y` „ÅßÁ∂öË°å„Åó„Åæ„Åô„ÄÇ

```
$ uv run dlt init rest_api duckdb
Creating a new pipeline with the dlt core source rest_api (Generic API Source)
NOTE: Beginning with dlt 1.0.0, the source rest_api will no longer be copied from the verified sources repo but imported from dlt.sources. You can provide the --eject flag to revert to the old behavior.
Do you want to proceed? [Y/n]: 

Your new pipeline rest_api is ready to be customized!
* Review and change how dlt loads your data in rest_api_pipeline.py
* Add credentials for duckdb and other secrets in ./.dlt/secrets.toml
* Add the required dependencies to pyproject.toml:
  dlt[duckdb]>=1.9.0
  If the dlt dependency is already added, make sure you install the extra for duckdb to it
  If you are using poetry you may issue the following command:
  poetry add dlt -E duckdb

* Read https://dlthub.com/docs/walkthroughs/create-a-pipeline for more information
$ tree
.
‚îú‚îÄ‚îÄ .dlt
‚îÇ   ‚îú‚îÄ‚îÄ config.toml
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ rest_api_pipeline.py
```

### [„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆÂÆüË°å](https://dlthub.com/docs/tutorial/rest-api#running-the-pipeline)

„Éâ„Ç≠„É•„É°„É≥„Éà„Å®Áï∞„Å™„Çä„ÄÅ`requirements.txt` „ÅØ„Åß„Åç„Å¶„ÅÑ„Å™„ÅÑ„ÅÆ„Åß„ÄÅÂá∫Âäõ„Åï„Çå„Åü„Å®„Åä„Çä„ÄÅ`pyproject.toml` „Å´‰æùÂ≠òÈñ¢‰øÇ„ÇíËøΩÂä†„Åó„Åæ„Åô„ÄÇ

```diff toml:pyproject.toml
@@ -4,4 +4,6 @@
 description = "Add your description here"
 readme = "README.md"
 requires-python = ">=3.12"
-dependencies = []
+dependencies = [
+    dlt[duckdb]>=1.9.0
+]
```

„Åì„ÅÆ„Åæ„ÅæÂãï„Åã„Åô„Å® github „ÅÆ rate Âà∂Èôê„Åß„Ç®„É©„Éº„Å´„Å™„Çã„Åü„ÇÅ„ÄÅgithub „Çí„Ç≥„É°„É≥„Éà„Ç¢„Ç¶„Éà„Åó„Å¶ÂÆüË°å„Åó„Åæ„Åô„ÄÇ

```diff py:rest_api_pipeline.py
@@ -149,5 +149,5 @@
 if __name__ == "__main__":
-    load_github()
+    # load_github()
     load_pokemon()
```

```
$ uv run rest_api_pipeline.py 
2025-04-06 08:11:11,321|[ERROR]|34180|140455832667968|dlt|utils.py|check_connection:21|Error checking connection: The following resources could not be found in source rest_api: {'not_existing_endpoint'}. Available resources are: {'location', 'pokemon', 'berry'}
2025-04-06 08:11:11,538|[WARNING]|34180|140455832667968|dlt|client.py|detect_paginator:312|Fallback paginator used: SinglePagePaginator at 7fbe5bb2aa50. Please provide right paginator manually.
Pipeline rest_api_pokemon load step completed in 0.17 seconds
1 load package(s) were loaded to destination duckdb and into dataset rest_api_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/rest-api/rest_api_pokemon.duckdb location to store data
Load package 1743927071.383116 is LOADED and contains no failed jobs
```

„Ç®„É©„Éº„ÇÑË≠¶Âëä„ÅåÂá∫„Å¶„ÅÑ„Çã„Åå„ÄÅ‰ª•‰∏ã„ÅÆ„Å®„Åä„Çä„ÄÅ1302 Ë°å„Åå DuckDB „Å´Ê†ºÁ¥ç„Åï„Çå„Åæ„Åó„Åü„ÄÇ

```
$ ~/.duckdb/cli/latest/duckdb 
v1.2.1 8e52ec4395
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
D .open rest_api_pokemon.duckdb
D .tables
_dlt_loads           _dlt_version         location           
_dlt_pipeline_state  berry                pokemon            
D select * from rest_api_data.pokemon;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            name             ‚îÇ                   url                    ‚îÇ   _dlt_load_id    ‚îÇ    _dlt_id     ‚îÇ
‚îÇ           varchar           ‚îÇ                 varchar                  ‚îÇ      varchar      ‚îÇ    varchar     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ bulbasaur                   ‚îÇ https://pokeapi.co/api/v2/pokemon/1/     ‚îÇ 1743927071.383116 ‚îÇ x5YRTG/PnZDqLA ‚îÇ
‚îÇ ivysaur                     ‚îÇ https://pokeapi.co/api/v2/pokemon/2/     ‚îÇ 1743927071.383116 ‚îÇ aOkyEKUQqT5I+g ‚îÇ
‚îÇ venusaur                    ‚îÇ https://pokeapi.co/api/v2/pokemon/3/     ‚îÇ 1743927071.383116 ‚îÇ LSFAjHFmu3nksw ‚îÇ
‚îÇ charmander                  ‚îÇ https://pokeapi.co/api/v2/pokemon/4/     ‚îÇ 1743927071.383116 ‚îÇ 9LH0ak/5YqWQ/Q ‚îÇ
‚îÇ charmeleon                  ‚îÇ https://pokeapi.co/api/v2/pokemon/5/     ‚îÇ 1743927071.383116 ‚îÇ KbgLYyCcZmWBZg ‚îÇ
‚îÇ charizard                   ‚îÇ https://pokeapi.co/api/v2/pokemon/6/     ‚îÇ 1743927071.383116 ‚îÇ HC8UYN6tXMi4LQ ‚îÇ
‚îÇ squirtle                    ‚îÇ https://pokeapi.co/api/v2/pokemon/7/     ‚îÇ 1743927071.383116 ‚îÇ Jp9dJ61hn5neEQ ‚îÇ
‚îÇ wartortle                   ‚îÇ https://pokeapi.co/api/v2/pokemon/8/     ‚îÇ 1743927071.383116 ‚îÇ 0b15UoCBQMu20Q ‚îÇ
‚îÇ blastoise                   ‚îÇ https://pokeapi.co/api/v2/pokemon/9/     ‚îÇ 1743927071.383116 ‚îÇ q3XR4Zx3UiWTPQ ‚îÇ
‚îÇ caterpie                    ‚îÇ https://pokeapi.co/api/v2/pokemon/10/    ‚îÇ 1743927071.383116 ‚îÇ h7Hs47VCSQpGaQ ‚îÇ
‚îÇ metapod                     ‚îÇ https://pokeapi.co/api/v2/pokemon/11/    ‚îÇ 1743927071.383116 ‚îÇ Xib1OanrtXydsw ‚îÇ
‚îÇ butterfree                  ‚îÇ https://pokeapi.co/api/v2/pokemon/12/    ‚îÇ 1743927071.383116 ‚îÇ wk79bEDFV7pgQQ ‚îÇ
‚îÇ weedle                      ‚îÇ https://pokeapi.co/api/v2/pokemon/13/    ‚îÇ 1743927071.383116 ‚îÇ u8HsCI6QhFUtrw ‚îÇ
‚îÇ kakuna                      ‚îÇ https://pokeapi.co/api/v2/pokemon/14/    ‚îÇ 1743927071.383116 ‚îÇ +6rbvqAFsFDTvw ‚îÇ
‚îÇ beedrill                    ‚îÇ https://pokeapi.co/api/v2/pokemon/15/    ‚îÇ 1743927071.383116 ‚îÇ /txiUsIf0Kd/vQ ‚îÇ
‚îÇ pidgey                      ‚îÇ https://pokeapi.co/api/v2/pokemon/16/    ‚îÇ 1743927071.383116 ‚îÇ j5wfFIfo1ZCVFQ ‚îÇ
‚îÇ pidgeotto                   ‚îÇ https://pokeapi.co/api/v2/pokemon/17/    ‚îÇ 1743927071.383116 ‚îÇ rwCzjLbfmGyHrw ‚îÇ
‚îÇ pidgeot                     ‚îÇ https://pokeapi.co/api/v2/pokemon/18/    ‚îÇ 1743927071.383116 ‚îÇ Q25KkTxI0cKF/w ‚îÇ
‚îÇ rattata                     ‚îÇ https://pokeapi.co/api/v2/pokemon/19/    ‚îÇ 1743927071.383116 ‚îÇ 37qoBEd+yA2azQ ‚îÇ
‚îÇ raticate                    ‚îÇ https://pokeapi.co/api/v2/pokemon/20/    ‚îÇ 1743927071.383116 ‚îÇ 9JZo2lO/tw7zow ‚îÇ
‚îÇ    ¬∑                        ‚îÇ                   ¬∑                      ‚îÇ         ¬∑         ‚îÇ       ¬∑        ‚îÇ
‚îÇ    ¬∑                        ‚îÇ                   ¬∑                      ‚îÇ         ¬∑         ‚îÇ       ¬∑        ‚îÇ
‚îÇ    ¬∑                        ‚îÇ                   ¬∑                      ‚îÇ         ¬∑         ‚îÇ       ¬∑        ‚îÇ
‚îÇ tatsugiri-droopy            ‚îÇ https://pokeapi.co/api/v2/pokemon/10258/ ‚îÇ 1743927071.383116 ‚îÇ glDbU62GwBf+Xw ‚îÇ
‚îÇ tatsugiri-stretchy          ‚îÇ https://pokeapi.co/api/v2/pokemon/10259/ ‚îÇ 1743927071.383116 ‚îÇ L6/XzsIRwmSYCQ ‚îÇ
‚îÇ squawkabilly-blue-plumage   ‚îÇ https://pokeapi.co/api/v2/pokemon/10260/ ‚îÇ 1743927071.383116 ‚îÇ ci2F5LvfTJG+AA ‚îÇ
‚îÇ squawkabilly-yellow-plumage ‚îÇ https://pokeapi.co/api/v2/pokemon/10261/ ‚îÇ 1743927071.383116 ‚îÇ t7nsdzb8iq2Yig ‚îÇ
‚îÇ squawkabilly-white-plumage  ‚îÇ https://pokeapi.co/api/v2/pokemon/10262/ ‚îÇ 1743927071.383116 ‚îÇ dhQevhXet2Ivng ‚îÇ
‚îÇ gimmighoul-roaming          ‚îÇ https://pokeapi.co/api/v2/pokemon/10263/ ‚îÇ 1743927071.383116 ‚îÇ kvk7X9K0cgAPyQ ‚îÇ
‚îÇ koraidon-limited-build      ‚îÇ https://pokeapi.co/api/v2/pokemon/10264/ ‚îÇ 1743927071.383116 ‚îÇ syWzCkYGTmxW4w ‚îÇ
‚îÇ koraidon-sprinting-build    ‚îÇ https://pokeapi.co/api/v2/pokemon/10265/ ‚îÇ 1743927071.383116 ‚îÇ QLRg03EXUlxBSQ ‚îÇ
‚îÇ koraidon-swimming-build     ‚îÇ https://pokeapi.co/api/v2/pokemon/10266/ ‚îÇ 1743927071.383116 ‚îÇ KgMSLmMgVUEYng ‚îÇ
‚îÇ koraidon-gliding-build      ‚îÇ https://pokeapi.co/api/v2/pokemon/10267/ ‚îÇ 1743927071.383116 ‚îÇ Gr2Q9K9iteTejw ‚îÇ
‚îÇ miraidon-low-power-mode     ‚îÇ https://pokeapi.co/api/v2/pokemon/10268/ ‚îÇ 1743927071.383116 ‚îÇ bIkyu2abvRVECA ‚îÇ
‚îÇ miraidon-drive-mode         ‚îÇ https://pokeapi.co/api/v2/pokemon/10269/ ‚îÇ 1743927071.383116 ‚îÇ UfBO+4Mfxw293w ‚îÇ
‚îÇ miraidon-aquatic-mode       ‚îÇ https://pokeapi.co/api/v2/pokemon/10270/ ‚îÇ 1743927071.383116 ‚îÇ Mr5sNDwmjyv70g ‚îÇ
‚îÇ miraidon-glide-mode         ‚îÇ https://pokeapi.co/api/v2/pokemon/10271/ ‚îÇ 1743927071.383116 ‚îÇ P7HIoBde+8ytgg ‚îÇ
‚îÇ ursaluna-bloodmoon          ‚îÇ https://pokeapi.co/api/v2/pokemon/10272/ ‚îÇ 1743927071.383116 ‚îÇ w70EJa8XFs6Rgw ‚îÇ
‚îÇ ogerpon-wellspring-mask     ‚îÇ https://pokeapi.co/api/v2/pokemon/10273/ ‚îÇ 1743927071.383116 ‚îÇ 2Z7lu3PHgNQPYw ‚îÇ
‚îÇ ogerpon-hearthflame-mask    ‚îÇ https://pokeapi.co/api/v2/pokemon/10274/ ‚îÇ 1743927071.383116 ‚îÇ pZWubGPwSSsKxQ ‚îÇ
‚îÇ ogerpon-cornerstone-mask    ‚îÇ https://pokeapi.co/api/v2/pokemon/10275/ ‚îÇ 1743927071.383116 ‚îÇ 6YNuuUZuJVz3Cg ‚îÇ
‚îÇ terapagos-terastal          ‚îÇ https://pokeapi.co/api/v2/pokemon/10276/ ‚îÇ 1743927071.383116 ‚îÇ +5y8clVXDqV7eQ ‚îÇ
‚îÇ terapagos-stellar           ‚îÇ https://pokeapi.co/api/v2/pokemon/10277/ ‚îÇ 1743927071.383116 ‚îÇ K9TmDZyyMsyynA ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1302 rows (40 shown)                                                                              4 columns ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
D .exit
```

### [„Éá„Éº„Çø„ÅÆË™øÊüª](https://dlthub.com/docs/tutorial/rest-api#exploring-the-data)

```
$ uv add streamlit
Resolved 72 packages in 388ms
Prepared 13 packages in 977ms
Installed 21 packages in 38ms
:
 + watchdog==6.0.0
$ uv run dlt pipeline rest_api_pokemon show
Found pipeline rest_api_pokemon in /home/ec2-user/.dlt/pipelines

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.48.149.30:8501
  External URL: http://18.178.73.138:8501
```

### [„Éá„Éº„Çø„ÅÆÁΩÆÊèõ](https://dlthub.com/docs/tutorial/rest-api#replacing-the-data)

```diff py:rest_api_pipeline.py
@@ -125,6 +125,7 @@
                         "limit": 1000,
                     },
                 },
+                "write_disposition": "replace", # Setting the write disposition to `replace
             },
             "resources": [
                 "pokemon",
```

### [„Éá„Éº„Çø„ÅÆ„Éû„Éº„Ç∏](https://dlthub.com/docs/tutorial/rest-api#merging-the-data)

```diff py:rest_api_pipeline.py
@@ -125,10 +125,20 @@ def load_pokemon() -> None:
                         "limit": 1000,
                     },
                 },
-                "write_disposition": "replace", # Setting the write disposition to `replace
+                # For the `berry` and `location` resources, we keep
+                # the `replace` write disposition
+                "write_disposition": "replace",
             },
             "resources": [
-                "pokemon",
+                # We create a specific configuration for the `pokemon` resource
+                # using a dictionary instead of a string to configure
+                # the primary key and write disposition
+                {
+                    "name": "pokemon",
+                    "primary_key": "name",
+                    "write_disposition": "merge",
+                },
+                # The `berry` and `location` resources will use the default
                 "berry",
                 "location",
             ],
```

```
$ uv run rest_api_pipeline.py 
2025-04-07 05:37:43,399|[ERROR]|31535|140519944869696|dlt|utils.py|check_connection:21|Error checking connection: The following resources could not be found in source rest_api: {'not_existing_endpoint'}. Available resources are: {'location', 'pokemon', 'berry'}
2025-04-07 05:37:43,602|[WARNING]|31535|140519944869696|dlt|client.py|detect_paginator:312|Fallback paginator used: SinglePagePaginator at 7fcd30ed1f10. Please provide right paginator manually.
Pipeline rest_api_pokemon load step completed in 0.24 seconds
1 load package(s) were loaded to destination duckdb and into dataset rest_api_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/rest-api/rest_api_pokemon.duckdb location to store data
Load package 1744004263.47209 is LOADED and contains no failed jobs
$ ~/.duckdb/cli/latest/duckdb 
v1.2.1 8e52ec4395
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
D .open rest_api_pokemon.duckdb
D select database_name, schema_name, table_name from duckdb_tables;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  database_name   ‚îÇ      schema_name      ‚îÇ     table_name      ‚îÇ
‚îÇ     varchar      ‚îÇ        varchar        ‚îÇ       varchar       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ berry               ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ location            ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ pokemon             ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ _dlt_loads          ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ _dlt_pipeline_state ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data         ‚îÇ _dlt_version        ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data_staging ‚îÇ pokemon             ‚îÇ
‚îÇ rest_api_pokemon ‚îÇ rest_api_data_staging ‚îÇ _dlt_version        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
D .exit
```

### [„Éá„Éº„Çø„ÅÆ„Ç§„É≥„ÇØ„É™„É°„É≥„Çø„É´„Å™„É≠„Éº„Éâ](https://dlthub.com/docs/tutorial/rest-api#loading-data-incrementally)

github „ÅØ rate Âà∂Èôê„Åß„Ç®„É©„Éº„Å´„Å™„Çã„Åü„ÇÅ„ÄÅ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ

## [SQL DB](https://dlthub.com/docs/tutorial/sql-database)

ÂêåÊßò„Å´„ÄÅuv „ÅÆ„ÉØ„Éº„ÇØ„Çπ„Éö„Éº„Çπ„ÅÆ„É°„É≥„Éê„Éº„Å®„Åó„Å¶„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ
dlt init „Åó„Åæ„Åô„ÄÇÈÄî‰∏≠„ÅÆË≥™Âïè„ÅØ Y „ÅßÁ∂öË°å„Åó„Åæ„Åô„ÄÇ

```
$ uv run dlt init sql_database duckdb
Creating a new pipeline with the dlt core source sql_database (Source that loads tables form any SQLAlchemy supported database, supports batching requests and incremental loads.)
NOTE: Beginning with dlt 1.0.0, the source sql_database will no longer be copied from the verified sources repo but imported from dlt.sources. You can provide the --eject flag to revert to the old behavior.
Do you want to proceed? [Y/n]: y

Your new pipeline sql_database is ready to be customized!
* Review and change how dlt loads your data in sql_database_pipeline.py
* Add credentials for duckdb and other secrets in ./.dlt/secrets.toml
* Add the required dependencies to pyproject.toml:
  dlt[duckdb,sql-database]>=1.9.0
  If the dlt dependency is already added, make sure you install the extra for duckdb to it
  If you are using poetry you may issue the following command:
  poetry add dlt -E duckdb

* Read https://dlthub.com/docs/walkthroughs/create-a-pipeline for more information
$ tree
.
‚îú‚îÄ‚îÄ .dlt
‚îÇ   ‚îú‚îÄ‚îÄ config.toml
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ sql_database_pipeline.py
```

ÂêåÊßò„Å´„ÄÅÂá∫Âäõ„Åï„Çå„Åü„Å®„Åä„Çä„ÄÅ`pyproject.toml` „Å´‰æùÂ≠òÈñ¢‰øÇ„ÇíËøΩÂä†„Åó„Åæ„Åô„ÄÇ

```diff toml:pyproject.toml
@@ -4,4 +4,6 @@
 description = "Add your description here"
 readme = "README.md"
 requires-python = ">=3.12"
-dependencies = []
+dependencies = [
+    "dlt[duckdb,sql-database]>=1.9.0"
+]
```

### [„Éë„Ç§„Éó„É©„Ç§„É≥„Çπ„ÇØ„É™„Éó„Éà„ÇíÊßãÊàê„Åô„Çã](https://dlthub.com/docs/tutorial/sql-database#2-configure-the-pipeline-script)

```diff py:sql_database_pipline.py
@@ -344,8 +344,26 @@
     info = pipeline.run(sql_alchemy_source)
     print(info)
 
+def load_tables_family_and_genome():
+
+    # Create a dlt source that will load tables "family" and "genome"
+    source = sql_database().with_resources("family", "genome")
+
+    # Create a dlt pipeline object
+    pipeline = dlt.pipeline(
+        pipeline_name="sql_to_duckdb_pipeline", # Custom name for the pipeline
+        destination="duckdb", # dlt destination to which the data will be loaded
+        dataset_name="sql_to_duckdb_pipeline_data" # Custom name for the dataset created in the destination
+    )
+
+    # Run the pipeline
+    load_info = pipeline.run(source)
+
+    # Pretty print load information
+    print(load_info)
 
 if __name__ == "__main__":
+    load_tables_family_and_genome()
     # Load selected tables with different settings
     # load_select_tables_from_database()
 
@@ -356,7 +374,7 @@
     # select_with_end_value_and_row_order()
 
     # Load tables with the standalone table resource
-    load_standalone_table_resource()
+    # load_standalone_table_resource()
 
     # Load all tables from the database.
     # Warning: The sample database is very large
```

### [Ë≥áÊ†ºÊÉÖÂ†±„ÇíËøΩÂä†„Åô„Çã](https://dlthub.com/docs/tutorial/sql-database#3-add-credentials)

```toml: .dlt/secrets.toml
[sources.sql_database.credentials]
drivername = "mysql+pymysql" # database+dialect
database = "Rfam"
password = ""
username = "rfamro"
host = "mysql-rfam-public.ebi.ac.uk"
port = 4497
```

### [‰æùÂ≠òÈñ¢‰øÇ„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åô„Çã](https://dlthub.com/docs/tutorial/sql-database#4-install-dependencies)

ÊúÄÂàù„Å´„ÇÑ„Å£„Å¶„Åó„Åæ„Å£„Åü„ÅÆ„Åß„ÄÅ`pymysql` „Å†„ÅëËøΩÂä†„Åó„Å¶„Åä„Åç„Åæ„Åô„ÄÇ

```
$ uv add pymysql
Resolved 76 packages in 268ms
Prepared 3 packages in 69ms
Installed 3 packages in 8ms
 + greenlet==3.1.1
 + pymysql==1.1.1
 + sqlalchemy==2.0.40
```

ÁµêÂ±Ä„ÄÅpyproject.toml „ÅÆÂ∑ÆÂàÜ„ÅØ„ÄÅ

```diff toml:pyproject.toml
@@ -4,4 +4,7 @@
 description = "Add your description here"
 readme = "README.md"
 requires-python = ">=3.12"
-dependencies = []
+dependencies = [
+    "dlt[duckdb,sql-database]>=1.9.0",
+    "pymysql>=1.1.1",
+]
```

### [„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíÂÆüË°å„Åô„Çã](https://dlthub.com/docs/tutorial/sql-database#5-run-the-pipeline)

```
$ uv run sql_database_pipeline.py 
Pipeline sql_to_duckdb_pipeline load step completed in 4.34 seconds
1 load package(s) were loaded to destination duckdb and into dataset sql_to_duckdb_pipeline_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/sql-db/sql_to_duckdb_pipeline.duckdb location to store data
Load package 1744006598.0197978 is LOADED and contains no failed jobs
$ ~/.duckdb/cli/latest/duckdb 
v1.2.1 8e52ec4395
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
D .open sql_to_duckdb_pipeline.duckdb
D select * from sql_to_duckdb_pipeline_data.genome;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    upid     ‚îÇ  assembly_acc   ‚îÇ assembly_version ‚îÇ wgs_acc ‚îÇ ‚Ä¶ ‚îÇ       created        ‚îÇ       updated        ‚îÇ    _dlt_load_id    ‚îÇ    _dlt_id     ‚îÇ
‚îÇ   varchar   ‚îÇ     varchar     ‚îÇ      int64       ‚îÇ varchar ‚îÇ   ‚îÇ timestamp with tim‚Ä¶  ‚îÇ timestamp with tim‚Ä¶  ‚îÇ      varchar       ‚îÇ    varchar     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RG000000001 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:0‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ RAoK+ODZamk3UQ ‚îÇ
‚îÇ RG000000002 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:0‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ drTISYKdQQ9B2g ‚îÇ
‚îÇ RG000000003 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:1‚Ä¶  ‚îÇ 2020-04-23 11:47:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ PpqHdR+rXcfIrw ‚îÇ
‚îÇ RG000000004 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:1‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ Gx2w3Lx18MhAJw ‚îÇ
‚îÇ RG000000005 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:2‚Ä¶  ‚îÇ 2020-04-23 11:46:2‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ drDFcqU8/hAPAw ‚îÇ
‚îÇ RG000000006 ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:2‚Ä¶  ‚îÇ 2020-04-23 11:52:3‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ JqAi5zqERM4xyQ ‚îÇ
‚îÇ RG000000007 ‚îÇ GCA_000413255.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:2‚Ä¶  ‚îÇ 2020-04-23 11:44:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ kf3xKgFBwCRY2w ‚îÇ
‚îÇ RG000000009 ‚îÇ GCF_000836845.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:4‚Ä¶  ‚îÇ 2020-04-23 11:49:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ zfrLC0X2XNk8iQ ‚îÇ
‚îÇ RG000000010 ‚îÇ GCF_000840125.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:4‚Ä¶  ‚îÇ 2020-04-23 11:46:2‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 77rxN5om2PJxRw ‚îÇ
‚îÇ RG000000011 ‚îÇ GCF_000847605.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:5‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 2FwYLNks8oC1IQ ‚îÇ
‚îÇ RG000000012 ‚îÇ GCF_000847825.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:11:5‚Ä¶  ‚îÇ 2020-04-23 11:46:3‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ ffZy/QDTO/AS4Q ‚îÇ
‚îÇ RG000000013 ‚îÇ GCF_000849085.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:0‚Ä¶  ‚îÇ 2020-04-23 11:47:2‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ hgJPzGytJjMW7Q ‚îÇ
‚îÇ RG000000016 ‚îÇ GCF_000849285.2 ‚îÇ                2 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:1‚Ä¶  ‚îÇ 2020-04-23 11:48:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ +ClNxwioiVyKAA ‚îÇ
‚îÇ RG000000019 ‚îÇ GCF_000853665.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:2‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ pkPzLyG19KqYoQ ‚îÇ
‚îÇ RG000000020 ‚îÇ GCF_000854685.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:3‚Ä¶  ‚îÇ 2020-04-23 11:49:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ RcAEzAhDMJZhYA ‚îÇ
‚îÇ RG000000021 ‚îÇ GCF_000854865.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:3‚Ä¶  ‚îÇ 2020-04-23 11:46:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ gs+pOektB6J8IA ‚îÇ
‚îÇ RG000000025 ‚îÇ GCF_000849985.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:5‚Ä¶  ‚îÇ 2020-04-23 11:46:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ lN2m551byT+kww ‚îÇ
‚îÇ RG000000026 ‚îÇ GCF_000852745.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-06-06 15:12:5‚Ä¶  ‚îÇ 2020-04-23 11:48:0‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ RO2pMMDgrpUP+w ‚îÇ
‚îÇ RG000000027 ‚îÇ NC_038861.1     ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2020-05-06 14:56:5‚Ä¶  ‚îÇ 2024-09-10 04:53:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 39PRFerp+sByMw ‚îÇ
‚îÇ RG000000028 ‚îÇ NC_032730.1     ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2020-05-06 14:56:5‚Ä¶  ‚îÇ 2024-09-10 04:56:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ v1HJFZlwxL/w+A ‚îÇ
‚îÇ      ¬∑      ‚îÇ      ¬∑          ‚îÇ                ¬∑ ‚îÇ  ¬∑      ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ      ¬∑      ‚îÇ      ¬∑          ‚îÇ                ¬∑ ‚îÇ  ¬∑      ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ      ¬∑      ‚îÇ      ¬∑          ‚îÇ                ¬∑ ‚îÇ  ¬∑      ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ UP001269074 ‚îÇ GCA_031320445.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:23:0‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 3N9L7w5vHw7Daw ‚îÇ
‚îÇ UP001269135 ‚îÇ GCA_031297675.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:29:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ R4AgPHTwF01Kuw ‚îÇ
‚îÇ UP001269161 ‚îÇ GCA_032416515.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:21:3‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ PpzQ8eKDQ2ZyjQ ‚îÇ
‚îÇ UP001269216 ‚îÇ GCA_031314795.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:22:0‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ z9Fpycw+xob8TQ ‚îÇ
‚îÇ UP001269251 ‚îÇ GCA_032423685.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:33:2‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 7rBXZviyfFCniA ‚îÇ
‚îÇ UP001269254 ‚îÇ GCA_031249865.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 11:07:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ gHS9qUlQJ/w60g ‚îÇ
‚îÇ UP001269288 ‚îÇ GCA_031298415.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:30:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 8UiqwxmwRImv1A ‚îÇ
‚îÇ UP001269304 ‚îÇ GCA_031579545.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:20:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ dnLPvoyA6qaoUA ‚îÇ
‚îÇ UP001269323 ‚îÇ GCA_031315845.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:23:4‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ aTc+gmY5ZiDT2g ‚îÇ
‚îÇ UP001269365 ‚îÇ GCA_031297925.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:19:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 4OsdbYElmRpmJg ‚îÇ
‚îÇ UP001269389 ‚îÇ GCA_031315295.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:23:1‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ xDaVRqSqQkNP8Q ‚îÇ
‚îÇ UP001269398 ‚îÇ GCA_031311295.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:26:3‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ Cb0ZVbpstoqOSg ‚îÇ
‚îÇ UP001269477 ‚îÇ GCA_031345405.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:19:2‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ kCVeFFc3kJsTzA ‚îÇ
‚îÇ UP001269491 ‚îÇ GCA_031313775.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:33:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 4jniuAfE2ukDJg ‚îÇ
‚îÇ UP001295947 ‚îÇ GCA_963583325.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:26:4‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 5cMRssA3IYvIuw ‚îÇ
‚îÇ UP001295980 ‚îÇ GCA_963583275.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:26:3‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 0uw4c/GtNPHWKw ‚îÇ
‚îÇ UP001296009 ‚îÇ GCA_963583145.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:29:4‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ v4LNPAv7TBgHXg ‚îÇ
‚îÇ UP001296230 ‚îÇ GCA_963583065.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-27 09:19:4‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ a3Xa1ncobXmLeg ‚îÇ
‚îÇ UP001296237 ‚îÇ GCA_963583445.1 ‚îÇ                1 ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2024-06-28 19:34:5‚Ä¶  ‚îÇ 2024-09-02 20:32:5‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ Tu6c6BRCZM8ORg ‚îÇ
‚îÇ x           ‚îÇ NULL            ‚îÇ             NULL ‚îÇ NULL    ‚îÇ ‚Ä¶ ‚îÇ 2017-05-15 11:09:5‚Ä¶  ‚îÇ 2020-04-23 11:53:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 0tjpW6cUvc+WbA ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 32169 rows (40 shown)                                                                                                         24 columns (8 shown) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
D select * from sql_to_duckdb_pipeline_data.family;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ rfam_acc ‚îÇ      rfam_id      ‚îÇ auto_wiki ‚îÇ     description      ‚îÇ ‚Ä¶ ‚îÇ       created        ‚îÇ       updated        ‚îÇ    _dlt_load_id    ‚îÇ    _dlt_id     ‚îÇ
‚îÇ varchar  ‚îÇ      varchar      ‚îÇ   int64   ‚îÇ       varchar        ‚îÇ   ‚îÇ timestamp with tim‚Ä¶  ‚îÇ timestamp with tim‚Ä¶  ‚îÇ      varchar       ‚îÇ    varchar     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RF00001  ‚îÇ 5S_rRNA           ‚îÇ      1302 ‚îÇ 5S ribosomal RNA     ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 20:41:4‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ OClMfuGcB5Wrvg ‚îÇ
‚îÇ RF00002  ‚îÇ 5_8S_rRNA         ‚îÇ      1303 ‚îÇ 5.8S ribosomal RNA   ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 20:47:0‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ qZDwAYdIO/camw ‚îÇ
‚îÇ RF00003  ‚îÇ U1                ‚îÇ      1304 ‚îÇ U1 spliceosomal RNA  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 20:57:1‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ K+Wl36xNJTWIqQ ‚îÇ
‚îÇ RF00004  ‚îÇ U2                ‚îÇ      1305 ‚îÇ U2 spliceosomal RNA  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 20:58:3‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ UAk9TdSlUWIC8A ‚îÇ
‚îÇ RF00005  ‚îÇ tRNA              ‚îÇ      1306 ‚îÇ tRNA                 ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 21:00:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ rXe0H2YAW/nzGA ‚îÇ
‚îÇ RF00006  ‚îÇ Vault             ‚îÇ      1307 ‚îÇ Vault RNA            ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:0‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ Jxk7lzwmRwCDsg ‚îÇ
‚îÇ RF00007  ‚îÇ U12               ‚îÇ      1308 ‚îÇ U12 minor spliceos‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:0‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ PDH7f4fn2cjg5g ‚îÇ
‚îÇ RF00008  ‚îÇ Hammerhead_3      ‚îÇ      1309 ‚îÇ Hammerhead ribozym‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:1‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ IDS8muklHuRsjg ‚îÇ
‚îÇ RF00009  ‚îÇ RNaseP_nuc        ‚îÇ      1310 ‚îÇ Nuclear RNase P      ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:1‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 5k/trucon72JVA ‚îÇ
‚îÇ RF00010  ‚îÇ RNaseP_bact_a     ‚îÇ      2441 ‚îÇ Bacterial RNase P ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ /xTM/2cIzDyN5A ‚îÇ
‚îÇ RF00011  ‚îÇ RNaseP_bact_b     ‚îÇ      2441 ‚îÇ Bacterial RNase P ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:5‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ AeKbJ2sqX1ARyQ ‚îÇ
‚îÇ RF00012  ‚îÇ U3                ‚îÇ      1312 ‚îÇ Small nucleolar RN‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:04:5‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ HKKoiog1fgcjOw ‚îÇ
‚îÇ RF00013  ‚îÇ 6S                ‚îÇ      2461 ‚îÇ 6S / SsrS RNA        ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:05:0‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ +DEnYRXhvYO2oA ‚îÇ
‚îÇ RF00014  ‚îÇ DsrA              ‚îÇ      1237 ‚îÇ DsrA RNA             ‚îÇ ‚Ä¶ ‚îÇ 2013-02-01 11:56:1‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ A42TH1HH7R4/qQ ‚îÇ
‚îÇ RF00015  ‚îÇ U4                ‚îÇ      1314 ‚îÇ U4 spliceosomal RNA  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:05:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ xj8cgaEmGDGM0Q ‚îÇ
‚îÇ RF00016  ‚îÇ SNORD14           ‚îÇ      1242 ‚îÇ Small nucleolar RN‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-02-01 11:56:2‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ auFI4SGhh2eBzA ‚îÇ
‚îÇ RF00017  ‚îÇ Metazoa_SRP       ‚îÇ      1315 ‚îÇ Metazoan signal re‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 22:07:5‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ E+gtShJ+PfZwNw ‚îÇ
‚îÇ RF00018  ‚îÇ CsrB              ‚îÇ      2460 ‚îÇ CsrB/RsmB RNA family ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 23:07:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ je4IWfYmNIftNQ ‚îÇ
‚îÇ RF00019  ‚îÇ Y_RNA             ‚îÇ      1317 ‚îÇ Y RNA                ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 23:07:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ Z6xD4ZC8vhXooA ‚îÇ
‚îÇ RF00020  ‚îÇ U5                ‚îÇ      1318 ‚îÇ U5 spliceosomal RNA  ‚îÇ ‚Ä¶ ‚îÇ 2013-10-03 23:08:4‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ I3QJhHgD/ybezg ‚îÇ
‚îÇ    ¬∑     ‚îÇ ¬∑                 ‚îÇ        ¬∑  ‚îÇ          ¬∑           ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ    ¬∑     ‚îÇ ¬∑                 ‚îÇ        ¬∑  ‚îÇ          ¬∑           ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ    ¬∑     ‚îÇ ¬∑                 ‚îÇ        ¬∑  ‚îÇ          ¬∑           ‚îÇ ¬∑ ‚îÇ          ¬∑           ‚îÇ          ¬∑           ‚îÇ         ¬∑          ‚îÇ       ¬∑        ‚îÇ
‚îÇ RF04290  ‚îÇ mir-1197          ‚îÇ      1287 ‚îÇ mir-1197 microRNA ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-23 23:12:4‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ G8z6tURzn78SYw ‚îÇ
‚îÇ RF04291  ‚îÇ mir-368           ‚îÇ      1287 ‚îÇ mir-368 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-23 23:47:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ uQXJEqWwI+PK9g ‚îÇ
‚îÇ RF04292  ‚îÇ mir-379           ‚îÇ      1287 ‚îÇ mir-379 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 00:00:1‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ KusLrBG8LTGjqw ‚îÇ
‚îÇ RF04293  ‚îÇ mir-889           ‚îÇ      1287 ‚îÇ mir-889 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 00:14:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ m0bCDPXGDZ666Q ‚îÇ
‚îÇ RF04294  ‚îÇ mir-3578          ‚îÇ      1287 ‚îÇ mir-3578 microRNA ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 00:22:2‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ fyLYP9F1uRsdYg ‚îÇ
‚îÇ RF04295  ‚îÇ mir-329           ‚îÇ      1287 ‚îÇ mir-329 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 00:58:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ D+3PjIw6tlulXg ‚îÇ
‚îÇ RF04296  ‚îÇ mir-485           ‚îÇ      1287 ‚îÇ mir-485 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 01:09:4‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ b+gnt7raOGOc0g ‚îÇ
‚îÇ RF04297  ‚îÇ mir-35_2          ‚îÇ      1287 ‚îÇ mir-35_2 microRNA ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 10:55:2‚Ä¶  ‚îÇ 2024-09-10 04:51:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ PkTj21tQpmaRpw ‚îÇ
‚îÇ RF04298  ‚îÇ mir-36_2          ‚îÇ      1287 ‚îÇ mir-36_2 microRNA ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 10:56:5‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ JwaN+kyG6J70fw ‚îÇ
‚îÇ RF04299  ‚îÇ MIR814            ‚îÇ      1287 ‚îÇ MIR814 microRNA pr‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 12:12:1‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 8nxpH2YvaTgk/Q ‚îÇ
‚îÇ RF04300  ‚îÇ mir-39            ‚îÇ      1287 ‚îÇ mir-39 microRNA pr‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-10-24 15:20:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ ITyPpnYuaU/ZHw ‚îÇ
‚îÇ RF04301  ‚îÇ mir-200           ‚îÇ      1287 ‚îÇ mir-200 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-11-21 12:46:0‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ vIfA9jEzkihQpQ ‚îÇ
‚îÇ RF04302  ‚îÇ mir-506           ‚îÇ      2235 ‚îÇ mir-506 microRNA p‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-11-27 13:46:2‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ aiEjYQDfbKQJDw ‚îÇ
‚îÇ RF04303  ‚îÇ MIR162_2          ‚îÇ      1287 ‚îÇ MIR162_2 microRNA ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2023-11-28 13:04:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ YbHE+qxzGCVpGA ‚îÇ
‚îÇ RF04305  ‚îÇ HCV_SL1412        ‚îÇ      2418 ‚îÇ Hepatitis C virus ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2024-04-08 15:25:1‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ ZrN6XN9KvBkTlw ‚îÇ
‚îÇ RF04306  ‚îÇ HCV_SL8001        ‚îÇ      2418 ‚îÇ Hepatitis C virus ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2024-04-08 15:35:2‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ 6qKRAp9LtyvY4g ‚îÇ
‚îÇ RF04307  ‚îÇ HCV_SL8670        ‚îÇ      2418 ‚îÇ Hepatitis C virus ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2024-04-08 16:11:3‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ zIyQtZBl7OmFqw ‚îÇ
‚îÇ RF04308  ‚îÇ HCV_SL2531-SL2549 ‚îÇ      2418 ‚îÇ Hepatitis C virus ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2024-04-10 15:16:5‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ jLvZqnyvNdqK0w ‚îÇ
‚îÇ RF04309  ‚îÇ HCV_J7880         ‚îÇ      2418 ‚îÇ Hepatitis C virus ‚Ä¶  ‚îÇ ‚Ä¶ ‚îÇ 2024-06-17 13:59:0‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ L7T1KucJBTXoMQ ‚îÇ
‚îÇ RF04310  ‚îÇ nqrA-II           ‚îÇ      2768 ‚îÇ nqrA-II ncRNA motif  ‚îÇ ‚Ä¶ ‚îÇ 2024-06-25 14:43:4‚Ä¶  ‚îÇ 2024-09-09 21:15:1‚Ä¶  ‚îÇ 1744006598.0197978 ‚îÇ YExDc03iO5RNSA ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4178 rows (40 shown)                                                                                                               37 columns (8 shown) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
D .exit
```

### [„Éá„Éº„Çø„ÇíÊé¢Á¥¢„Åô„Çã](https://dlthub.com/docs/tutorial/sql-database#6-explore-the-data)

```
$ uv add streamlit
Resolved 76 packages in 387ms
Audited 67 packages in 0.02ms
$ uv run dlt pipeline sql_to_duckdb_pipeline show
Found pipeline sql_to_duckdb_pipeline in /home/ec2-user/.dlt/pipelines

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.48.149.30:8501
  External URL: http://18.178.73.138:8501
```

### [ÁΩÆÊèõ„Åß„É≠„Éº„Éâ](https://dlthub.com/docs/tutorial/sql-database#load-with-replace)

```diff py:sql_database_pipline.py
@@ -357,7 +357,7 @@
     )
 
     # Run the pipeline
-    load_info = pipeline.run(source)
+    load_info = pipeline.run(source, write_disposition="replace") # Set write_disposition to load the data with "replace"
 
     # Pretty print load information
     print(load_info)
```
```
$ uv run sql_database_pipeline.py 
Pipeline sql_to_duckdb_pipeline load step completed in 4.47 seconds
1 load package(s) were loaded to destination duckdb and into dataset sql_to_duckdb_pipeline_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/sql-db/sql_to_duckdb_pipeline.duckdb location to store data
Load package 1744007697.087969 is LOADED and contains no failed jobs
```

### [„Éû„Éº„Ç∏„Åß„É≠„Éº„Éâ](https://dlthub.com/docs/tutorial/sql-database#load-with-merge)

```diff py:sql_database_pipline.py
@@ -349,6 +349,10 @@
     # Create a dlt source that will load tables "family" and "genome"
     source = sql_database().with_resources("family", "genome")
 
+    # specify different loading strategy for each resource using apply_hints
+    source.family.apply_hints(write_disposition="merge", primary_key="rfam_id") # merge table "family" on column "rfam_id"
+    source.genome.apply_hints(write_disposition="merge", primary_key="upid") # merge table "genome" on column "upid"
+
     # Create a dlt pipeline object
     pipeline = dlt.pipeline(
         pipeline_name="sql_to_duckdb_pipeline", # Custom name for the pipeline
@@ -357,7 +361,7 @@
     )
 
     # Run the pipeline
-    load_info = pipeline.run(source, write_disposition="replace") # Set write_disposition to load the data with "replace"
+    load_info = pipeline.run(source)
 
     # Pretty print load information
     print(load_info)
```
```
$ uv run sql_database_pipeline.py 
Pipeline sql_to_duckdb_pipeline load step completed in 4.84 seconds
1 load package(s) were loaded to destination duckdb and into dataset sql_to_duckdb_pipeline_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/sql-db/sql_to_duckdb_pipeline.duckdb location to store data
Load package 1744007926.344812 is LOADED and contains no failed jobs
```

### [„Ç§„É≥„ÇØ„É™„É°„É≥„Çø„É´„Å´„É≠„Éº„Éâ](https://dlthub.com/docs/tutorial/sql-database#8-load-data-incrementally)

```diff py:sql_database_pipline.py
@@ -349,9 +349,8 @@ 
     # Create a dlt source that will load tables "family" and "genome"
     source = sql_database().with_resources("family", "genome")
 
-    # specify different loading strategy for each resource using apply_hints
-    source.family.apply_hints(write_disposition="merge", primary_key="rfam_id") # merge table "family" on column "rfam_id"
-    source.genome.apply_hints(write_disposition="merge", primary_key="upid") # merge table "genome" on column "upid"
+    # only load rows whose "updated" value is greater than the last pipeline run
+    source.family.apply_hints(incremental=dlt.sources.incremental("updated"))
 
     # Create a dlt pipeline object
     pipeline = dlt.pipeline(
```
```
$ uv run sql_database_pipeline.py 
2025-04-07 06:42:45,784|[WARNING]|36348|140550876481344|dlt|__init__.py|_check_duplicate_cursor_threshold:591|Large number of records (832) sharing the same value of cursor field 'updated'. This can happen if the cursor field has a low resolution (e.g., only stores dates without times), causing many records to share the same cursor value. Consider using a cursor column with higher resolution to reduce the deduplication state size.
Pipeline sql_to_duckdb_pipeline load step completed in 4.71 seconds
1 load package(s) were loaded to destination duckdb and into dataset sql_to_duckdb_pipeline_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/sql-db/sql_to_duckdb_pipeline.duckdb location to store data
Load package 1744008155.7218933 is LOADED and contains no failed jobs
```

## [File System](https://dlthub.com/docs/tutorial/filesystem)

ÂêåÊßò„Å´„ÄÅuv „ÅÆ„ÉØ„Éº„ÇØ„Çπ„Éö„Éº„Çπ„ÅÆ„É°„É≥„Éê„Éº„Å®„Åó„Å¶„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ
dlt init „Åó„Åæ„Åô„ÄÇÈÄî‰∏≠„ÅÆË≥™Âïè„ÅØ Y „ÅßÁ∂öË°å„Åó„Åæ„Åô„ÄÇ

```
$ uv run dlt init filesystem duckdb
Creating a new pipeline with the dlt core source filesystem (Reads files in s3, gs or azure buckets using fsspec and provides convenience resources for chunked reading of various file formats)
NOTE: Beginning with dlt 1.0.0, the source filesystem will no longer be copied from the verified sources repo but imported from dlt.sources. You can provide the --eject flag to revert to the old behavior.
Do you want to proceed? [Y/n]: y

Your new pipeline filesystem is ready to be customized!
* Review and change how dlt loads your data in filesystem_pipeline.py
* Add credentials for duckdb and other secrets in ./.dlt/secrets.toml
* Add the required dependencies to pyproject.toml:
  dlt[duckdb,filesystem]>=1.9.0
  If the dlt dependency is already added, make sure you install the extra for duckdb to it
  If you are using poetry you may issue the following command:
  poetry add dlt -E duckdb

* Read https://dlthub.com/docs/walkthroughs/create-a-pipeline for more information
$ tree
.
‚îú‚îÄ‚îÄ .dlt
‚îÇ   ‚îú‚îÄ‚îÄ config.toml
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ filesystem_pipeline.py
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ pyproject.toml
```

ÂêåÊßò„Å´„ÄÅÂá∫Âäõ„Åï„Çå„Åü„Å®„Åä„Çä„ÄÅpyproject.toml „Å´‰æùÂ≠òÈñ¢‰øÇ„ÇíËøΩÂä†„Åó„Åæ„Åô„ÄÇ

```diff toml:pyproject.toml
@@ -4,4 +4,6 @@
 description = "Add your description here"
 readme = "README.md"
 requires-python = ">=3.12"
-dependencies = []
+dependencies = [
+    "dlt[duckdb,filesystem]>=1.9.0"
+]
```

### [„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆ‰ΩúÊàê](https://dlthub.com/docs/tutorial/filesystem#2-creating-the-pipeline)

```py: filesystem_pipeline.py
import dlt
from dlt.sources.filesystem import filesystem, read_csv

files = filesystem(bucket_url="gs://filesystem-tutorial", file_glob="encounters*.csv")
reader = (files | read_csv()).with_name("encounters")
pipeline = dlt.pipeline(pipeline_name="hospital_data_pipeline", dataset_name="hospital_data", destination="duckdb")

info = pipeline.run(reader)
print(info)
```

### [„Éï„Ç°„Ç§„É´„Ç∑„Çπ„ÉÜ„É†„ÇΩ„Éº„Çπ„ÅÆË®≠ÂÆö](https://dlthub.com/docs/tutorial/filesystem#3-configuring-the-filesystem-source)

```toml:.dlt/secrets.toml
[sources.filesystem.credentials]
client_email = "public-access@dlthub-sandbox.iam.gserviceaccount.com"
project_id = "dlthub-sandbox"
private_key = "-----BEGIN PRIVATE KEY-----\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQDGWsVHJRjliojx\nTo+j1qu+x8PzC5ZHZrMx6e8OD6tO8uxMyl65ByW/4FZkVXkS4SF/UYPigGN+rel4\nFmySTbP9orva4t3Pk1B9YSvQMB7V5IktmTIW9Wmdmn5Al8Owb1RehgIidm1EX/Z9\nLr09oLpO6+jUu9RIP2Lf2mVQ6tvkgl7UOdpdGACSNGzRiZgVZDOaDIgH0Tl4UWmK\n6iPxhwZy9YC2B1beLB/NU+F6DUykrEpBzCFQTqFoTUcuDAEvuvpU9JrU2iBMiOGw\nuP3TYSiudhBjmauEUWaMiqWAgFeX5ft1vc7/QWLdI//SAjaiTAu6pTer29Q0b6/5\niGh0jRXpAgMBAAECggEAL8G9C9MXunRvYkH6/YR7F1T7jbH1fb1xWYwsXWNSaJC+\nagKzabMZ2KfHxSJ7IxuHOCNFMKyex+pRcvNbMqJ4upGKzzmeFBMw5u8VYGulkPQU\nPyFKWRK/Wg3PZffkSr+TPargKrH+vt6n9x3gvEzNbqEIDugmRTrVsHXhvOi/BrYc\nWhppHSVQidWZi5KVwDEPJjDQiHEcYI/vfIy1WhZ8VuPAaE5nMZ1m7gTdeaWWKIAj\n/p2ZkLgRdCY8vNkfaNDAxDbvH+CMuTtOw55GydzsYYiofANS6xZ8CedGkYaGi82f\nqGdLghX61Sg3UAb5SI36T/9XbuCpTf3B/SMV20ew8QKBgQDm2yUxL71UqI/xK9LS\nHWnqfHpKmHZ+U9yLvp3v79tM8XueSRKBTJJ4H+UvVQrXlypT7cUEE+sGpTrCcDGL\nm8irtdUmMvdi7AnRBgmWdYKig/kgajLOUrjXqFt/BcFgqMyTfzqPt3xdp6F3rSEK\nHE6PQ8I3pJ0BJOSJRa6Iw2VH1QKBgQDb9WbVFjYwTIKJOV4J2plTK581H8PI9FSt\nUASXcoMTixybegk8beGdwfm2TkyF/UMzCvHfuaUhf+S0GS5Zk31Wkmh1YbmFU4Q9\nm9K/3eoaqF7CohpigB0wJw4HfqNh6Qt+nICOMCv++gw7+/UwfV72dCqr0lpzfX5F\nAsez8igTxQKBgDsq/axOnQr+rO3WGpGJwmS8BKfrzarxGXyjnV0qr51X4yQdfGWx\nV3T8T8RC2qWI8+tQ7IbwB/PLE3VURg6PHe6MixXgSDGNZ7KwBnMOqS23/3kEXwMs\nhn2Xg+PZeMeqW8yN9ldxYqmqViMTN32c5bGoXzXdtfPeHcjlGCerVOEFAoGADVPi\nRjkRUX3hTvVF6Gzxa2OyQuLI1y1O0C2QCakrngyI0Dblxl6WFBwDyHMYGepNnxMj\nsr2p7sy0C+GWuGDCcHNwluQz/Ish8SW28F8+5xyamUp/NMa0fg1vwS6AMdeQFbzf\n4T2z/MAj66KJqcV+8on5Z+3YAzVwaDgR56pdmU0CgYBo2KWcNWAhZ1Qa6sNrITLV\nGlxg6tWP3OredZrmKb1kj5Tk0V+EwVN+HnKzMalv6yyyK7SWq1Z6rvCye37vy27q\nD7xfuz0c0H+48uWJpdLcsxpTioopsRPayiVDKlHSe/Qa+MEjAG3ded5TJiC+5iSw\nxWJ51y0wpme0LWgzzoLbRw==\n-----END PRIVATE KEY-----\n"
```
```toml:.dlt/config.toml
[sources.filesystem]
bucket_url="gs://filesystem-tutorial"
```

### [„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆÂÆüË°å](https://dlthub.com/docs/tutorial/filesystem#4-running-the-pipeline)

„Åì„ÅÆ„Åæ„Åæ„ÅÑ„Åè„Å®Ê≠ª„Å¨„ÅÆ„Åß„ÄÅgs „ÅÆ‰æùÂ≠òÈñ¢‰øÇ„ÇíËøΩÂä†„Åó„Åæ„Åô„ÄÇ

```
$ uv add dlt[gs]
Resolved 106 packages in 83ms
Prepared 16 packages in 54ms
Installed 16 packages in 19ms
:
 + rsa==4.9
```

```
$ uv run python filesystem_pipeline.py
Pipeline hospital_data_pipeline load step completed in 3.29 seconds
1 load package(s) were loaded to destination duckdb and into dataset hospital_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/filesystem/hospital_data_pipeline.duckdb location to store data
Load package 1744009708.2871656 is LOADED and contains no failed jobs
```

### [„Éá„Éº„Çø„ÅÆË™øÊüª](https://dlthub.com/docs/tutorial/filesystem#5-exploring-the-data)

„Åì„Çå„Åæ„Åß„Å®‰∏ÄÁ∑í„Åß„Åô„Åå„ÄÅ

```
$ uv add streamlit
Resolved 106 packages in 46ms
Audited 93 packages in 0.05ms
$ uv run dlt pipeline hospital_data_pipeline show
Found pipeline hospital_data_pipeline in /home/ec2-user/.dlt/pipelines

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.48.149.30:8501
  External URL: http://18.178.73.138:8501
```

### [„É≠„Éº„Éâ„Éá„Éº„Çø„ÅÆËøΩÂä†„ÄÅÁΩÆÊèõ„ÄÅ„Éû„Éº„Ç∏](https://dlthub.com/docs/tutorial/filesystem#6-appending-replacing-and-merging-loaded-data)

„Éö„Éº„Ç∏„Å´„ÅÇ„Çã `merge` „ÅÆÂ†¥Âêà

```diff py:filesystem_pipeline.py
@@ -3,7 +3,8 @@ 
 
 files = filesystem(bucket_url="gs://filesystem-tutorial", file_glob="encounters*.csv")
 reader = (files | read_csv()).with_name("encounters")
+reader.apply_hints(primary_key="id")
 pipeline = dlt.pipeline(pipeline_name="hospital_data_pipeline", dataset_name="hospital_data", destination="duckdb")
 
-info = pipeline.run(reader)
+info = pipeline.run(reader, write_disposition="merge")
 print(info)
```
```
$ uv run python filesystem_pipeline.py
Pipeline hospital_data_pipeline load step completed in 3.52 seconds
1 load package(s) were loaded to destination duckdb and into dataset hospital_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/filesystem/hospital_data_pipeline.duckdb location to store data
Load package 1744010182.1334121 is LOADED and contains no failed jobs
```

### [„Éá„Éº„Çø„Çí„Ç§„É≥„ÇØ„É™„É°„É≥„Çø„É´„Å´„É≠„Éº„Éâ„Åô„Çã](https://dlthub.com/docs/tutorial/filesystem#7-loading-data-incrementally)

„Åì„Åì„ÅØ„ÄÅÔºíÊÆµÈöé„ÅßÂÆüË°å„Åó„Åæ„Åô„ÄÇ

```diff py:filesystem_pipeline.py
@@ -2,6 +2,7 @@ 
 from dlt.sources.filesystem import filesystem, read_csv
 
 files = filesystem(bucket_url="gs://filesystem-tutorial", file_glob="encounters*.csv")
+files.apply_hints(incremental=dlt.sources.incremental("modification_date"))
 reader = (files | read_csv()).with_name("encounters")
 reader.apply_hints(primary_key="id")
 pipeline = dlt.pipeline(pipeline_name="hospital_data_pipeline", dataset_name="hospital_data", destination="duckdb")
```
```
$ uv run python filesystem_pipeline.py
Pipeline hospital_data_pipeline load step completed in 3.47 seconds
1 load package(s) were loaded to destination duckdb and into dataset hospital_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/filesystem/hospital_data_pipeline.duckdb location to store data
Load package 1744011013.538883 is LOADED and contains no failed jobs
```

ÔºëÂõûÂÆüË°å„Åó„Å¶„Åã„Çâ„ÄÅ‰ª•‰∏ã„ÅÆ‰øÆÊ≠£„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ

```diff py:filesystem_pipeline.py
@@ -4,7 +4,7 @@ 
 files = filesystem(bucket_url="gs://filesystem-tutorial", file_glob="encounters*.csv")
 files.apply_hints(incremental=dlt.sources.incremental("modification_date"))
 reader = (files | read_csv()).with_name("encounters")
-reader.apply_hints(primary_key="id")
+reader.apply_hints(primary_key="id", incremental=dlt.sources.incremental("STOP"))
 pipeline = dlt.pipeline(pipeline_name="hospital_data_pipeline", dataset_name="hospital_data", destination="duckdb")
 
 info = pipeline.run(reader, write_disposition="merge")
```
```
$ uv run python filesystem_pipeline.py
Pipeline hospital_data_pipeline load step completed in 0.07 seconds
1 load package(s) were loaded to destination duckdb and into dataset hospital_data
The duckdb destination used duckdb:////home/ec2-user/work/mds/dlt-getting-started/filesystem/hospital_data_pipeline.duckdb location to store data
Load package 1744011132.9863658 is LOADED and contains no failed jobs
```

‰ª•Èôç„ÅØ„ÄÅ„Çµ„É≥„Éó„É´„Éá„Éº„Çø„ÇíË™øÈÅî„Åó„Å™„ÅÑ„Å®„ÅÑ„Åë„Å™„ÅÑ„Çà„ÅÜ„Å™„ÅÆ„Åß„ÄÅ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ

# „Åä„Çè„Çä„Å´

„ÅÑ„Åã„Åå„Åß„Åó„Åü„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ
„Åì„Çå„Åæ„Åß„ÅÆ„Éá„Éº„ÇøÈÄ£Êê∫„Åß„ÅØ„ÄÅ„Åæ„Åö„ÄÅ„Ç™„É™„Ç∏„Éä„É´„ÅÆ„Éá„Éº„Çø„Çí `‰∏≠Á´ãÁöÑ„Å™Á´ãÂ†¥` „ÅßË™≠„ÅøËæº„Çì„Åß„ÄÅ„Åù„Çå„ÇíÂä†Â∑•„Åó„Å¶„ÄÅÊ†ºÁ¥ç„Åô„Çã„Å®„ÅÑ„ÅÜ ETL „ÅÆÂá¶ÁêÜ„Çí„Ç§„É°„Éº„Ç∏„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„Åå„ÄÅdlt „Åß„ÅØ„ÄÅË™≠„ÇÄ„Å®ÂêåÊôÇ„Å´Êõ∏„ÅçËæº„ÅøÂÖà„Å´Êõ∏„ÅçËæº„ÇÅ„Çã„Çà„ÅÜ„Å´Ëá™Âãï„ÅßÊï¥„Åà„Å¶„ÄÅ„Å©„Çì„Å©„ÇìÊõ∏„ÅÑ„Å¶„ÅÑ„Åë„Çã„ÅÆ„ÅåÊñ∞ÈÆÆ„Åß„Åó„Åü„ÄÇ

ÂæåÁ∂ö„ÅÆ dbt „Åå„ÄÅÊ®ôÊ∫ñÂåñ„ÄÅ‰∏≠ÈñìÂΩ¢Âºè„ÄÅÊúÄÁµÇ„ÅÆ„Éì„Ç∏„Éç„ÇπÂΩ¢Âºè„ÅÆ„Çà„ÅÜ„Å´Âä†Â∑•„Åó„Å¶„ÅÑ„Åè„ÅÆ„Åß„ÄÅdlt „ÅØ„ÄÅÊ∫ñÂÇô„Å´ÊôÇÈñì„Çí„Åã„Åë„Åö„Å´„ÄÅ„Åù„ÅÆ„Åæ„Åæ„Ç¢„ÉÉ„Éó„Åô„Çã„Å®„ÅÑ„ÅÜÊÄùÊÉ≥„Å™„Çì„Å†„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇELT „ÅØ„ÄÅETL „ÅÆ T „ÅåÂæå„Çç„Å´Ë°å„Å£„Åü„Å†„Åë„Å®„ÅÑ„ÅÜ„ÅÆ„ÅØÁîò„Åã„Å£„Åü„Çà„ÅÜ„Åß„Åô„ÄÇT „ÅåÂæå„Çç„Å´Ë°å„Åè„Åì„Å®„Å´„Çà„Å£„Å¶„ÄÅE „Å® L „ÅÆÂá¶ÁêÜ„ÇÇÂ§â„Çè„Å£„Å¶„ÅÑ„Åè„ÄÇ„ÉÜ„Éº„Éñ„É´‰∏Ä„Å§‰∏Ä„Å§„ÄÅÂêçÂâç„ÇíÁ¢∫Ë™ç„Åó„Å¶„ÄÅ„Çπ„Ç≠„Éº„ÉûÂÆöÁæ©„Åó„Å¶„ÄÅ„Å®„Åã„Åß„ÅØ„Å™„Åè„ÄÅ„Éá„Éº„Çø„ÇΩ„Éº„Çπ„Å´„Å§„Å™„ÅÑ„Å†„Çâ„ÄÅ„Åæ„Å®„ÇÅ„Å¶„Éâ„Ç´„É≥„Å®Ê©üÊ¢∞ÁöÑ„Å´„Ç≥„Éî„Éº„Åó„Åæ„Åó„Çá„ÅÜ„Å®ÁêÜËß£„Åó„Åæ„Åó„Åü„ÄÇ

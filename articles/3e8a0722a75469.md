---
title: "Data Fabric - バラバラのデータを活用する考え方"
emoji: "🧵"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["datafabric", "データファブリック", "metadata", "dx", "architecture"]
published: false
publication_name: "robon"
---

# はじめに

DX による競争優位の確立が、最も優先度の高い経営課題の一つであることには疑問の余地がありません。DX は、『データとデジタル技術を活用して変革を起こす』ことですが、デジタル技術を活用するのはともかくとして、「データの活用」できてますか？

活用できない理由は、データがバラバラだからではありませんか？
- データが管理されている場所がバラバラ
- データへのアクセス方法がバラバラ
- データの形式がバラバラ

DX という言葉が登場する以前から、バラバラのデータと戦い続けてきたのではありませんか？
- 統合データベースを作ろう（最近は MDM などと呼ばれているかもしれません）
- 分析用のデータウェアハウスを作ろう
- ETLツール（またはエンタープライズ・サービス・バス）を導入しよう
- 全部データレイクに入れることにしよう（今度こそ…）

どうなってますか？
- 時間がかかる（完成したときには要件が変わっている）
- お金がかかる（初回はなんとかなっても、メンテナンスや拡張は難しい）
- ヒトがいない（要件を考える人、設計する人、開発する人、活用する人）
- ●●用のデータレイクなど、バラバラに複数のデータレイクができてしまった…

# Data Fabric

この言葉を誰がいつから使い始めたのか、いろいろなサイトにいろいろな記述がされています。真偽がわからないので、ここでは引用しませんが、Gartner社の「[2022年の戦略的テクノロジのトップ・トレンド](https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20211117)」が、この言葉を広めたことは間違いなさそうです。

コンセンサスのとれた定義があるわけでもないようなのですが、
```
データがバラバラであっても、『欲しいデータを』『欲しい時に』『欲しい場所で』入手できる
```
というコンセプトは概ね共通のようです。この記事では、また、弊社、株式会社 ROBON では、これを Data Fabic の定義としたいと思います。

「そんなことをどうやって実現するのか？」

DX です。これまで苦労してきたデータマネジメント業務でも『データとデジタル技術を活用して変革を起こす』のです。

![](/images/3e8a0722a75469/datafabric.png)

## Metadata

Data Fabric では、データとデジタル技術を活用して、データマネージメントに変革を起こす。

ここでのデータは、どのようなデータになるのでしょう？

もちろん、「興味のある対象についてのデータ」です。ここで興味のある対象はデータですから、「データについてのデータ」を活用する必要があります。

>「データについてのデータ」のように、なんらかの概念について、その概念自体を対象とする同じ種類の概念を表す英語の接頭辞が `meta` です。ですから、「データについてのデータ」を「メタデータ」と呼びます。

つまり、データマネージメント業務を DX で改革するために活用すべきデータは「メタデータ」ということになります。

## Metadata Management

メタデータをマネジメントできていますか？

ここでいう「メタデータ」とは、例えば、リレーショナルデータベースの「テーブル仕様書」だったり、コンピュータ上や送受信されるデータファイルの「ファイル定義書」「項目定義書」のようなデータを説明するデータのことです。

こんな状態ではありませんか？
- そんなものはない
- どこにあるかわからない
- 印刷された仕様書がリアルなファイルに綴じられてキャビネットのどこかにある
- 「バラバラに開発されたシステム」の「バラバラな開発ベンダー」から「バラバラの書式の EXCEL ファイル」で納品されたものが、「CD-ROM やファイルサーバのどこかに」バラバラに保存されている
- 開発当時のものはあるが、その後の改修や追加開発では更新していない。変更分だけが別にファイルとして納品されているので、解読する必要がある

どうせメタデータは、
- 欲しい時には見つからない
- 見つかったとしても正しいかどうかわからない

そんなメタデータを作ったり、直したりしたくない。なぜなら、
- 時間がかかる
- お金がかかる
- ヒトがいない

[はじめに](#はじめに) の最後の問題に戻ってしまいました。

仮に、人間によるメタデータ・マネジメントは崩壊していたとしても、マネジメントされているメタデータは存在します。それは、データをマネジメントしているツールの中です。ご承知と思いますが、RDBMS というのは、Relational DataBase Management System の略です。RDBMS は、データをマネジメントするために、自分のデータのメタデータを持っていて、使っています。ですから、「このテーブルのこの項目を抽出せよ」という SQL の命令を正しく処理することができるのです。

他のデータを管理しているツールも同様に管理しているデータのメタデータを保持しています。ですから、最新の正しいメタデータは、それぞれのツールが持っているものをベースにすれば良いのです。全てのツールからメタデータを収集してくれるツールがあれば、今のバラバラなデータに対する正しいメタデータを揃えることができます。システムが自動的に収集してくれれば、「時間はかからず」「お金もたいしてかからず」「ヒトを必要とせず」にメタデータを作ったり、直したりできます。

これまでのヒトが EXCEL ファイルにテーブルの定義を入力するというメタデータ・マネジメントから、データを管理するツールとメタデータを管理するツールの連携によって、メタデータをマネジメントするという新しい業務へ変革を行いませんか？

バラバラなデータを管理するそれぞれのツールからメタデータを収集して、一元管理すると、全てのデータのメタデータを使って、『欲しいデータ』を見つけることができます。『欲しいデータ』は、まだ見つけていないのですから、ボンヤリとしていて正確な名前もわかりません。それを人工知能（AI）や機械学習（ML）を使って見つけるための支援をすることもできます。AI や ML は蓄積したデータを使って精度を高めることができますので、正しいメタデータをたくさん集めれば集めるほど、どんどん効率が良くなっていくのです。

このようにして、「作りたくなくて」「直したくない」メタデータのマネジメント業務を改革することで、[Data Fabric](#data-fabric) の定義の最初の一つ『欲しいデータ』を発見できます。また、同時に『欲しいデータ』に対するデータ、メタデータも入手することができます。

データレイクにもメタデータを管理しているデータカタログのようなツールがありますので、それらのツールからもメタデータを収集することで、マルチクラウドであったり、複数のデータレイクが存在している場合にも、その全てのメタデータを収集することが可能です。

## その先へ

メタデータをマネジメントすることで『欲しいデータ』を見つけることが可能になります。このメタデータを管理するツールを全ての関係者に共有すれば、だれでも『欲しいデータを』『欲しい時に』『欲しい場所で』見つけることができます。

でも、見つけられるだけでなく、また、関係者という人間だけでなく、『必要としているシステムが動いている場所で』『必要としている時』にデータを持っているシステムとデータを必要としているシステムの間でデータの連携を行う必要があります。

ここで問題になるのは、欲しいデータのボリュームと鮮度です。大量データの場合、データの受け渡しそのものにも時間が必要となるので、最新のデータを要求することは難しいかもしれません。必ずしも最新である必要がなければ、現時点で有効なデジタル技術を活用すれば良いと思います。例えば、それはデータレイクかもしれません。

ご承知と思いますが、ETL というのは、元データを持っているシステムから抽出・収集（Extract）したデータを変換・加工（Transform）して、そのデータを必要としているシステムへ配信・送出（Load）を行うツールです。このうち、設計や開発に時間が必要なのは、主に Transform だと思います。データレイクを中継する場合、元データを持っているシステムから Extract したものをそのままデータレイクへ Load します。そのデータを必要としているシステムが必要な Transform をすれば連携することができます。

この ETL とは順番の違う ELT ツールをデータレイクと組み合わせることは、もう一つの問題である「レガシーシステムへの影響」を最小限にした連携を比較的実現しやすいものと考えます。

一方、データのボリュームは小さいけれども、鮮度の高さが要求される場合もあるでしょう。少し古いですが、経済産業省で公開されている [対話に向けた検討ポイント集 第3章](https://www.meti.go.jp/press/2020/12/20201228004/20201228004-7.pdf) を読む前なら、「リアルタイム連携であれば、WebAPI が良いと思います」で終了していたかもしれませんが、この国の DX が進まない大きな理由の一つがレガシーシステムにあるのであれば、レガシーシステムからのリアルタイム連携をどのように実現するかについても、DX による変革が必要です。どのように実現するかについては、別途、考えを記事にまとめたいと思います。

# おわりに

株式会社 ROBON では、この記事で説明した Data Fabric を実現するための仕組みを提供していきます。

`ランディングページがオープンしたら、ここにランディングページへのリンクと`
`製品発表のプレスリリースのリンクを貼る`
`Mashu への直接リンクはちょっと検討`

ご期待ください。

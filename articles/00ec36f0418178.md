---
title: "AOSS ã¨ Bedrock ã§ AI æ¤œç´¢"
emoji: "ğŸ§ "
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["opensearch", "aoss", "bedrock", "embedding", "rag"]
published: true
publication_name: "robon"
---
# ã¯ã˜ã‚ã«
AOSS ã¨ã¯ã€Amazon OpenSearch Serverless ã§ã‚ã‚‹ã€‚å¼Šç¤¾ã§ã¯ã€è£½å“å†…ã®å…¨æ–‡æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã—ã¦ã€AOSS ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã€‚ã‚„ã¯ã‚Šã€é‹ç”¨çš„ã«ã‚‚ä¿å®ˆçš„ã«ã‚‚ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé‡ã®å¢—æ¸›ã‚„AZéšœå®³ã‚’æ°—ã«ã—ãªãã¦è‰¯ã„ã€ŒçœŸã«ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ã€ã®ä¸–ç•Œã‚’çµŒé¨“ã—ã¦ã—ã¾ã†ã¨ã€ã‚‚ã†å…ƒã«ã¯æˆ»ã‚Œãªã„ã€‚

ä¸–ã®ä¸­ã¯ã€ã‚„ã¯ã‚Š AI ã§ã‚ã‚‹ã€‚ãã‚ãã‚ãªã‚“ã¨ã‹ã—ã‚ˆã†ã¨ [Bedrock Knowledgebase](https://aws.amazon.com/jp/bedrock/knowledge-bases/) ãªã©ã‚’èª¿æŸ»ã—ã¦ã¿ãŸã®ã§ã‚ã‚‹ãŒã€åˆ¥ã« Chat ãªã‚“ã‹ã—ãªãã¦ã‚‚ã€AI æ¤œç´¢ãŒã§ãã‚Œã°ã„ã„ã‚“ã ã‚ˆãªãâ€¦ã¨æ€ã£ã¦ã„ãŸã¨ã“ã‚ã€

https://aws.amazon.com/jp/about-aws/whats-new/2025/08/amazon-opensearch-serverless-ai-connectors-hybrid-search/

ã§ã‚ã‚‹ã€‚2025å¹´8æœˆ7æ—¥ã€‚ã“ã‚Œã‹ã‚‚ã—ã‚Œãªã„â€¦ã€‚

# ã‚„ã£ã¦ã¿ãŸ
ã¨ã¯ã„ãˆã€ä½•ã®çŸ¥è­˜ã‚‚ãªã„çŠ¶æ…‹ã§å§‹ã‚ã‚‰ã‚Œã‚‹ã»ã©ã€ç”˜ãã¯ãªã„ã“ã¨ã¯æ‰¿çŸ¥ã—ã¦ã‚‹ã®ã§ã€ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‚’æ¢ã™ã“ã¨ã«ã—ãŸã€‚

## ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹
ã‚ã£ãŸã€‚

https://aws.amazon.com/jp/blogs/news/introduction-to-amazon-opensearch-service-workshop-jp

2025å¹´3æœˆ21æ—¥ã€‚ã„ã„ã‹ã‚‚ã—ã‚Œãªã„â€¦ã€‚

## çœŸã«ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰
OpenSearch Service ã‚’ OpenSearch Serverless ã«ç½®ãæ›ãˆã€SageMager ã‚’ Bedrock ã«ç½®ãæ›ãˆã‚ˆã†ã€‚ã“ã‚ŒãŒä»Šå›ã®ç¸›ã‚Šã§ã‚ã‚‹ã€‚

## çµè«–
ç½®ãæ›ãˆãŸã€‚

https://github.com/take0a/aoss-bedrock-workshop

ä»¥ä¸Šã€‚ã§ã‚ã‚‹ãŒã€ã“ã“ã§ã‚‚èª¬æ˜ã—ã¦ã¿ã‚‹ã€‚ã“ã“ã§ã¯ã€ `4-ai-search.ipynb` ã ã‘ã«ã™ã‚‹ãŒã€ä»–ã®å†…å®¹ã‚‚å¤§å¤‰å‹‰å¼·ã«ãªã£ãŸã€‚ã‚ã‚ŠãŒã¨ã† AWSã€‚

## æº–å‚™
ç’°å¢ƒã¯ã€ã“ã‚“ãªæ„Ÿã˜ã§ã€VSCode ã‹ã‚‰ EC2 ã« Remote Development ã§ Jupyter Notebook ã‚’é–‹ã„ã¦ã€EC2 ã® IAM ãƒ­ãƒ¼ãƒ«ã§ AOSS ã¨ Bedrock ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã€‚ï¼ˆã“ã‚Œã ã‘ã€‚å¤§é‡ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ CloudFormation ã§ä½œæˆã™ã‚‹ã®ã«æŠµæŠ—ã®ã‚ã‚‹æ–¹ã‚‚å®‰å¿ƒï½—ï¼‰

![](/images/00ec36f0418178/architecture-with-bedrock.png =500x)

### EC2
æœ€è¿‘ã¯ Python ã¨ã„ãˆã°ã€`uv` ãªã®ã§ã€[ã“ã“](https://docs.astral.sh/uv/getting-started/installation/)ã¿ã¦ã€uv ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

ä¸Šã®ç½®ãæ›ãˆãŸ Workshop ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½¿ã†ãªã‚‰ã€
```
git clone https://github.com/take0a/aoss-bedrock-workshop.git
cd aoss-bedrock-workshop
uv sync
```

VSCode ã«ã¯ã€ä»¥ä¸‹ã® Extension ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚
- [Python](https://marketplace.visualstudio.com/items?itemName=ms-python.python)
- [Jupyter](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)

### IAM
ä»¥ä¸‹ã® IAM Role ã« AOSS ã¨ Bedrock ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚
- ä¸Šè¨˜ã®è¸ã¿å°ã«ã™ã‚‹ EC2 ã‚’ä½œã‚‹ã¨ãã«ç´ã¥ã‘ãŸ IAM Role
- ç®¡ç†ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’æ“ä½œã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼

ã“ã‚Œã¨ã¯åˆ¥ã«ã€AOSS ãŒ Bedrock ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã® IAM Role ã‚’ä½œæˆã™ã‚‹ã€‚ã“ã“ã§ã€Œä¿¡é ¼ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€ã¯ã€`ml.opensearchservice.amazonaws.com` ãªã®ã§æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ã¨ã„ã†ã‹çµæ§‹ç„¡ç†ã‚²ãƒ¼ã ã¨æ€ã†ã€‚[ã“ã“](https://docs.aws.amazon.com/ja_jp/opensearch-service/latest/developerguide/ml-amazon-connector.html)ã«æ›¸ã„ã¦ã‚ã‚‹ãŒâ€¦ã€‚ãƒãƒªã‚·ãƒ¼ã¯ã€ã“ã®ãƒ–ãƒ­ã‚°ã®ç¯„å›²ã§ã‚ã‚Œã°ã€InvokeModel ãŒã§ãã‚Œã° OKã€‚

### AOSS
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œã‚‹ã®ã§ã‚ã‚‹ãŒã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œã‚‹å‰ã«ã€AOSS ã®ãƒãƒªã‚·ãƒ¼ã‚’ä½œã‚‹ã€‚åµã¨é¶ã®ã‚ˆã†ã§ã‚ã‚‹ãŒã€ãƒãƒªã‚·ãƒ¼ã‚’ä½œã‚‹å‰ã«ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®åå‰ã‚’æ±ºã‚ã¦ãŠãã®ãŒå‰ã€‚ã“ã“ã§ã¯ã€`workshop-vector` ã§äºˆå®šã™ã‚‹ã€‚ã“ã‚Œã¯ã€ä»¥ä¸‹ã®ãƒãƒªã‚·ãƒ¼ã‚’å‰²ã‚Šå½“ã¦ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚

æ—¢ã«ã€AOSS ã®æ¤œç´¢ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ã¦ã„ã¦ã€é–‹ç™ºç’°å¢ƒã ã‹ã‚‰ OCU ã¯æœ€å°ã® 2 ã«è¨­å®šã—ã¦ã„ã‚‹å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã¨ 4 ã«ä¸Šã’ãªã„ã¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒä½œã‚Œãªã„ã€‚ã¾ãŸã€AOSS ã‚’ä½¿ã£ã¦ã„ãªã„å ´åˆã€ã ã„ã¶å®‰ãã¯ãªã£ãŸãŒã€ãã‚Œãªã‚Šã«è²»ç”¨ãŒã‹ã‹ã‚‹ã®ã§ã€äº‹å‰ã«ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã™ã‚‹ã€‚

#### Encryption policy
ãƒªã‚½ãƒ¼ã‚¹ã‚’ `workshop*` ã®ã‚ˆã†ã«ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã€‚æš—å·åŒ–ã¯ã€ä»–ã®ã‚­ãƒ¼ã§ã‚‚è‰¯ã„ã§ã™ãŒã€AWSæ‰€æœ‰ã‚­ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã§è‰¯ã„ã€‚

#### Network policy
`workshop*` ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã€‚ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆã™ã‚‹ã ã‘ãªã‚‰ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã§ã‚‚è‰¯ã„ã‹ã‚‚ã€‚

#### Data access policy
ãƒ—ãƒªãƒ³ã‚·ãƒ‘ãƒ«ã¯ã€ä¸Šã® IAM ã§ AOSS ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ä»˜ä¸ã—ãŸ EC2 ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã® Role ã«ã™ã‚‹ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯ã€`collection/workshop*` ã¨ `index/workshop*/*` ã¨ `model/workshop*/*` ã®ï¼“ã¤ã§ã‚ã‚‹ãŒã€å°ã•ã„ç”»é¢ã§ã¯ã€æœ€å¾Œã® model ãŒè¦‹ãˆãªã„ï¼†ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã‚‚å‡ºãªã„çŠ¶æ…‹ã«ãªã‚‹ã€‚ã¾ãŸã€ï¼“ã¤è¨±å¯ã—ãŸã„ã®ã«ã€ï¼‘ãƒ«ãƒ¼ãƒ«ã®ã‚¢ã‚¤ãƒ†ãƒ ã¯ï¼’ã¤ã¾ã§ã¨æ€’ã‚‰ã‚Œã‚‹ã€‚ã¶ã¡ãã‚Œã‚‹ã¨ã“ã‚ã§ã¯ã‚ã‚‹ãŒã€ã“ã“ã¯ã€ã‚°ãƒƒã¨å ªãˆã¦ã€ãƒ«ãƒ¼ãƒ«ã‚’ï¼’ã¤ã«åˆ†ã‘ã¦ç™»éŒ²ã™ã‚‹ã€‚

### Bedrock
`Amazon Titan Text Embeddings V2` ã‚’ä½¿ã„ãŸã„ã®ã§ã€ç®¡ç†ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã® `ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹` ã§ `ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¯èƒ½` ã®å ´åˆã«ã¯ã€`ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ` ã—ã¦ã€`ã‚¢ã‚¯ã‚»ã‚¹ãŒä»˜ä¸ã•ã‚Œã¾ã—ãŸ` ã«ã™ã‚‹ã€‚

## ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯ã€Bedrock Knowledgebase ã§ã‚‚åˆ©ç”¨å¯èƒ½ã§ã—ãŸã®ã§ã€2025å¹´8æœˆ7æ—¥ã®ç™ºè¡¨åˆ†ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ä»Šå›ã®ãƒ–ãƒ­ã‚°ã®ç¯„å›²å…¨ä½“ã®åŸºæœ¬ãªã®ã§ã€ã“ã“ã‹ã‚‰ã‚„ã‚Šã¾ã—ã‚‡ã†ã€‚

### Bedrock å‘¼ã³å‡ºã—ã®ãƒã‚§ãƒƒã‚¯
[ã“ã“](https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModelWithResponseStream_TitanTextEmbeddings_section.html)ã®ã‚³ãƒ”ãƒšã§ã‚ã‚‹ãŒã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ã€Bedrock ã®è¨­å®šã‚„ IAM ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãŠãã€‚

```py
# Generate and print an embedding with Amazon Titan Text Embeddings V2.

import boto3
import json

# Create a Bedrock Runtime client in the AWS Region of your choice.
client = boto3.client("bedrock-runtime", region_name="us-east-1")

# Set the model ID, e.g., Titan Text Embeddings V2.
model_id = "amazon.titan-embed-text-v2:0"

# The text to convert to an embedding.
input_text = "Please recommend books with a theme similar to the movie 'Inception'."

# Create the request for the model.
native_request = {"inputText": input_text}

# Convert the native request to JSON.
request = json.dumps(native_request)

# Invoke the model with the request.
response = client.invoke_model(modelId=model_id, body=request)

# Decode the model's native response body.
model_response = json.loads(response["body"].read())

# Extract and print the generated embedding and the input text token count.
embedding = model_response["embedding"]
input_token_count = model_response["inputTextTokenCount"]

print("\nYour input:")
print(input_text)
print(f"Number of input tokens: {input_token_count}")
print(f"Size of the generated embedding: {len(embedding)}")
print("Embedding:")
print(embedding)
```

### AOSS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
ä»¥ä¸‹ã®ã‚ˆã†ã«ã€`knn_vector` ã‚¿ã‚¤ãƒ—ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç”¨æ„ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã€‚

```py
payload = {
  "mappings": {
    "properties": {
      "id": {"type": "keyword"},
      "question": {"type": "text", "analyzer": "custom_kuromoji_analyzer"},
      "context":  {"type": "text", "analyzer": "custom_kuromoji_analyzer"},
      "answers":  {"type": "text", "analyzer": "custom_kuromoji_analyzer"},
      "question_embedding": {
        "type": "knn_vector",
        "dimension": 1024,
        "space_type": "l2",
        "method": {
          "name": "hnsw",
          "engine": "faiss",
        }
      },
      "context_embedding": {
        "type": "knn_vector",
        "dimension": 1024,
        "space_type": "l2",
        "method": {
          "name": "hnsw",
          "engine": "faiss",
        },
      }
    }
  },
  "settings": {
    "index.knn": True,
    "analysis": {
      "analyzer": {
        "custom_kuromoji_analyzer": {
          "char_filter": ["icu_normalizer"],
          "filter": [
              "kuromoji_baseform",
              "custom_kuromoji_part_of_speech"
          ],
          "tokenizer": "kuromoji_tokenizer",
          "type": "custom"
        }
      },
      "filter": {
        "custom_kuromoji_part_of_speech": {
          "type": "kuromoji_part_of_speech",
          "stoptags": ["æ„Ÿå‹•è©,ãƒ•ã‚£ãƒ©ãƒ¼","æ¥é ­è¾","ä»£åè©","å‰¯è©","åŠ©è©","åŠ©å‹•è©","å‹•è©,ä¸€èˆ¬,*,*,*,çµ‚æ­¢å½¢-ä¸€èˆ¬","åè©,æ™®é€šåè©,å‰¯è©å¯èƒ½"]
        }
      }
    }
  }
}
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã‚’æŒ‡å®š
index_name = "jsquad-knn"

try:
    # æ—¢ã«åŒåã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ã„ã£ãŸã‚“å‰Šé™¤ã‚’è¡Œã†
    print("# delete index")
    response = opensearch_client.indices.delete(index=index_name)
    print(json.dumps(response, indent=2))
except Exception as e:
    print(e)

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
response = opensearch_client.indices.create(index_name, body=payload)
response
```

### ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¯ã€AOSS å†…éƒ¨ã‹ã‚‰ã§ã¯ãªãã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã€AOSS ã¸ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å‰ã«è¡Œã†ã“ã¨ã«ãªã‚‹ã€‚

```py
def get_df_with_embeddings(input_df, field_mappings, model_id, bedrock_region, batch_size):
    output_df = pd.DataFrame([]) #create empty dataframe
    df_list = np.array_split(input_df, input_df.shape[0]/batch_size)
    for df in tqdm(df_list):
        index = df.index #backup index number
        df_with_embeddings = df
        for field_mapping in field_mappings:
            input_field_name = field_mapping["InputFieldName"]
            embedding_field_name = field_mapping["EmbeddingFieldName"]
            payload = {
                "inputText": df_with_embeddings[input_field_name].values.tolist()[0]
            }
            body = json.dumps(payload)
            bedrock_runtime_client = boto3.client("bedrock-runtime", region_name=bedrock_region)
            response = bedrock_runtime_client.invoke_model(modelId=model_id, body=body)
            model_response = json.loads(response["body"].read())
            embeddings = [model_response["embedding"]]

            df_with_embeddings = pd.concat([df_with_embeddings.reset_index(drop=True), pd.Series(embeddings,name=embedding_field_name).reset_index(drop=True)],axis=1) #join embedding results to source dataframe
            df_with_embeddings = df_with_embeddings.set_index(index) #restore index number

        output_df = pd.concat([output_df, df_with_embeddings])
    return output_df

valid_df_with_embeddings = get_df_with_embeddings(
    input_df=valid_df,
    field_mappings=[
        {"InputFieldName": "question", "EmbeddingFieldName": "question_embedding"},
        {"InputFieldName": "context", "EmbeddingFieldName": "context_embedding"},
    ],
    model_id=model_id,
    bedrock_region=default_region,
    batch_size=1
)
```

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰
å‰é …ã§ã€Pandas ã® DataFrame ä¸Šã«æº–å‚™ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ [AWS SDK for Pandas](https://github.com/aws/aws-sdk-pandas) ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚

```py
index_name = "jsquad-knn"
response = wr.opensearch.index_df(
    client=opensearch_client,
    df=valid_df_with_embeddings,
    use_threads=True,
    index=index_name,
    bulk_size=200, # 200 ä»¶ãšã¤æ›¸ãè¾¼ã¿
    refresh=False,
)
```

### ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«ã‚‚å¤–éƒ¨ã§ä½œæˆã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ãŸãŒã€æ¤œç´¢ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã® `query` ã‚‚å¤–éƒ¨ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦æ¤œç´¢ã™ã‚‹ã€‚

```py
index_name = "jsquad-knn"
model_id = "amazon.titan-embed-text-v2:0"
query = "æ—¥æœ¬ã§æ¢…é›¨ãŒãªã„å ´æ‰€ã¯ï¼Ÿ"

def text_to_embedding(text, region_name, model_id):
    payload = {
        "inputText": text
    }
    body = json.dumps(payload)
    bedrock_runtime_client = boto3.client("bedrock-runtime", region_name)
    response = bedrock_runtime_client.invoke_model(modelId = model_id, body=body)
    model_response = json.loads(response["body"].read())
    return model_response["embedding"]

vector = text_to_embedding(text=query, region_name=default_region, model_id=model_id)
k = 10

payload = {
  "query": {
    "knn": {
      "question_embedding": {
        "vector": vector,
        "k": k
      }
    }
  },
  "_source": False,
  "fields": ["question", "answers", "context"],
  "size": k
}
response = opensearch_client.search(
    index=index_name,
    body=payload
)
pd.json_normalize(response["hits"]["hits"])
```

## ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¤œç´¢
ã“ã“ã‹ã‚‰ã¯ã€ã‚„ã£ã¨ 2025å¹´8æœˆ7æ—¥ã®ç™ºè¡¨åˆ†ã€‚ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ä½•ãŒé•ã†ã®ã‹ï¼Ÿ
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç™»éŒ²æ™‚ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ä½œæˆã‚‚ã€æ¤œç´¢æ™‚ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ä½œæˆã‚‚ AOSS å´ã§ã‚„ã£ã¦ãã‚Œã‚‹ã®ãŒã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¤œç´¢ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨åŒã˜ã§ã‚ã‚‹ã€‚Workshop ã§ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åå‰ã ã‘ `jsquad-neural-search` ã«å¤‰æ›´ã—ãŸã€‚

### ã‚³ãƒã‚¯ã‚¿ã®ä½œæˆ
ã“ã‚Œã‚‚ 2025å¹´8æœˆ7æ—¥ã®ç™ºè¡¨åˆ†ã®æ–°æ©Ÿèƒ½ã€‚
AOSS ãŒ Bedrock ã¸ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®ã‚³ãƒã‚¯ã‚¿ã‚’ä½œæˆã™ã‚‹ã€‚

```py
embedding_model_name = "amazon.titan-embed-text-v2:0"

payload = {
  "name": embedding_model_name, 
  "description": "Remote connector for " + embedding_model_name,
  "version": 1, 
  "protocol": "aws_sigv4",
  "credential": {
    "roleArn": opensearch_connector_role_arn
  },
  "parameters": {
    "region": default_region,
    "service_name": "bedrock",
    "model": embedding_model_name,
    "dimensions": 1024,
    "normalize": True,
    "embeddingTypes": ["float"],    
  },
  "actions": [
    {
      "action_type": "predict",
      "method": "POST",
      "headers": {
          "content-type": "application/json",
          "x-amz-content-sha256": "required",
      },
      "url": "https://bedrock-runtime.${parameters.region}.amazonaws.com/model/${parameters.model}/invoke",
      "pre_process_function": "connector.pre_process.bedrock.embedding",
      "request_body": '{ "inputText": "${parameters.inputText}", "dimensions": ${parameters.dimensions}, "normalize": ${parameters.normalize}, "embeddingTypes": ${parameters.embeddingTypes} }',
      "post_process_function": "connector.post_process.bedrock.embedding",
    }
  ]
}

# API ã®å®Ÿè¡Œ
response = opensearch_client.http.post("/_plugins/_ml/connectors/_create", body=payload)
# çµæœã‹ã‚‰ã‚³ãƒã‚¯ã‚¿ ID ã‚’å–å¾—
opensearch_embedding_connector_id = response["connector_id"]
```

### ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²
å‰é …ã®ã‚³ãƒã‚¯ã‚¿ã‚’æŒ‡å®šã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ã™ã‚‹ã€‚
ã“ã“ã‹ã‚‰å…ˆã¯ã€ã‚³ãƒã‚¯ã‚¿ã®IDã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«ã®IDã§å‚ç…§ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚

```py
payload = {
    "name": embedding_model_name,
    "description": embedding_model_name,
    "function_name": "remote",
    "connector_id": opensearch_embedding_connector_id
}
response = opensearch_client.http.post("/_plugins/_ml/models/_register?deploy=true", body=payload)
opensearch_embedding_model_id = response['model_id']
```

ï¼ˆãã‚‹ãã‚‹ã—ã¦ã‚‹ã®ã¯ã€ã‚«ãƒƒãƒˆã—ã¾ã—ãŸã€‚ï¼‰

### Ingestion pipeline ã®ä½œæˆ
Ingestion pipeline ã¯ã€ãƒ‡ãƒ¼ã‚¿ç™»éŒ²æ™‚ã«ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’è¡Œã†ã€‚
ãã®éš›ã€`text_embedding` `processor` ã¨ã—ã¦ã€ä¸Šã§ç™»éŒ²ã—ãŸ `model_id` ã‚’ä¿æŒã—ã¦ã„ã‚‹ã€‚

```py
payload = {
  "processors": [
    {
      "text_embedding": {
        "model_id": opensearch_embedding_model_id,
        "field_map": {
            "question": "question_embedding",
            "context": "context_embedding"
        }
      }
    }
  ]
}

ingestion_pipeline_id = f"{embedding_model_name}_neural_search_ingestion"

response = opensearch_client.http.put("/_ingest/pipeline/" + ingestion_pipeline_id, body=payload)
print(response)
```

### Search pipeline ã®ä½œæˆ
Search pipeline ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¯ã‚¨ãƒªã«å¤‰æ›ã™ã‚‹ã€‚ãã®éš›ã€`neural_query_enricher` `request_processor` ã¨ã—ã¦ã€å‰é …ã® Ingestion pipeline ã¨åŒã˜ã `model_id` ã‚’ä¿æŒã—ã¦ã„ã‚‹ã€‚

```py
payload={
  "request_processors": [
    {
      "neural_query_enricher" : {
        "default_model_id": opensearch_embedding_model_id
      }
    }
  ]
}
# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ID ã®æŒ‡å®š
search_pipeline_id = f"{embedding_model_name}_neural_search_query"
# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ API ã®å‘¼ã³å‡ºã—
response = opensearch_client.http.put("/_search/pipeline/" + search_pipeline_id, body=payload)
print(response)
```

### ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¤œç´¢ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
ä¸Šã® `ingestion_pipeline_id` ã‚’æŒ‡å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã‚’ã™ã‚‹ã“ã¨ã§ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãªãŒã‚‰ã€ç™»éŒ²ãŒè¡Œã‚ã‚Œã‚‹ã€‚
ã‚ªãƒªã‚¸ãƒŠãƒ«ã¯ã€`use_threads=True` ã§ `bulk_size=10` ã§ã‚ã£ãŸãŒã€ã“ã“ã¾ã§æ¸›ã‚‰ã•ãªã„ã¨é€”ä¸­ã§æ­»ã‚“ã§ã—ã¾ã†ã®ã§ã€ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã§ï¼‘ä»¶ãšã¤ã®é€æ¬¡å‡¦ç†ã«ãªã£ãŸã€‚çµæœã€15åˆ†å‰å¾Œã‹ã‹ã‚‹ã€‚ï¼ˆã®ã§ã€æœ¬å½“ã¯ãªã‚“ã¨ã‹ã—ãŸã„ï¼‰

```py
index_name = "jsquad-neural-search"
response = wr.opensearch.index_df(
    client=opensearch_client,
    df=valid_df,
    use_threads=False,
    index=index_name,
    bulk_size=1, # 1 ä»¶ãšã¤æ›¸ãè¾¼ã¿
    refresh=False,
    pipeline=ingestion_pipeline_id
)
```

### ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¤œç´¢
ä¸Šã® `search_pipeline_id` ã‚’æŒ‡å®šã—ã¦ã€æ¤œç´¢ã‚’è¡Œã†ã“ã¨ã§ã€ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã—ã¦ã€æ¤œç´¢ãŒè¡Œã‚ã‚Œã‚‹ã€‚

```py
index_name = "jsquad-neural-search"
query = "æ—¥æœ¬ã§æ¢…é›¨ãŒãªã„å ´æ‰€ã¯ï¼Ÿ"
payload = {
  "size": 10,
  "query": {
    "neural": {
      "question_embedding": {
        "query_text": query, 
        # model_id ã®æŒ‡å®šã¯è¡Œã‚ãªã„
        "k": 10
      }
    }
  },
  "_source" : False,
  "fields": ["question", "answers",  "context"]
}
# æ¤œç´¢ API ã‚’å®Ÿè¡Œ
response = opensearch_client.search(
    body = payload,
    index = index_name,
    filter_path = "hits.hits",
    search_pipeline = search_pipeline_id # æ–°ãŸã«è¿½åŠ 
)

# çµæœã‚’è¡¨ç¤º
pd.json_normalize(response["hits"]["hits"])
```

## ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
ã“ã‚Œã‚‚ 2025å¹´8æœˆ7æ—¥ã®ç™ºè¡¨åˆ†ã€‚
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸæ¤œç´¢ã§ã‚ã‚‹ã€‚

```py
index_name = "jsquad-neural-search"
query = "æ—¥æœ¬ã§æ¢…é›¨ãŒãªã„åœ°åŸŸã¯ï¼Ÿ"

payload = {
  "size": 10,
  "query": {
    "hybrid": {
      "queries": [
        {
          "match": {
            "question": {
              "query": query,
              "operator": "and"
            }
          }
        },
        {
          "neural": {
            "question_embedding": {
              "query_text": query, # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—
              "k": 10 # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ã«è¿‘ã„ãƒ™ã‚¯ãƒˆãƒ«ã®ã†ã¡ä¸Šä½ 10 ä»¶ã‚’è¿”å´
            }
          }
        }
      ]
    }
  },
  "_source" : False,
  "fields": ["question", "answers",  "context"]
}
# æ¤œç´¢ API ã‚’å®Ÿè¡Œ
response = opensearch_client.search(
    body = payload,
    index = index_name,
    filter_path = "hits.hits",
    search_pipeline = hybrid_search_pipeline_id 
)

# çµæœã‚’è¡¨ç¤º
pd.json_normalize(response["hits"]["hits"])
```

# ãŠã‚ã‚Šã«
ã“ã‚Œã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆã®å…¨æ–‡æ¤œç´¢ã«ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã¾ã§ãã‚‹ã¨ã€AI æ¤œç´¢æ„ŸãŒã‚ã‚‹ã‚ˆã­ï¼Ÿ

Workshop ã«ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ¤œç´¢ã‚‚ã‚ã£ãŸã®ã ãŒã€æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã® Bedrock ã§ã¯ã€æ—¥æœ¬èªã‚¹ãƒ‘ãƒ¼ã‚¹æ¤œç´¢ãŒå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨ã§ããªã„ã‚ˆã†ãªã®ã§ã€Bedrock ã® update å¾…ã¡ã¨ã„ã†ã“ã¨ã«ã—ãŸã„ã¨æ€ã†ã€‚

ã¾ãŸã€Workshop ã«ã¯ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚‚ã‚ã£ãŸã®ã ãŒã€ã“ã¡ã‚‰ã¯ã€Bedrock ä¸Šã® `amazon.rerank-v1:0` ã¸ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ã¨å®Ÿè¡Œã¾ã§ã¯ã§ããŸãŒã€`rerank` `response_processor` ã¨ã—ã¦ pipeline ã«ç™»éŒ²ã™ã‚‹éš›ã«ã€`Invalid processor type rerank` ã«ãªã£ã¦ã—ã¾ã£ãŸã®ã§ã€ãŸã¶ã‚“ã€AOSS ã® update å¾…ã¡ã€‚
